{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkYyORZPMpiq",
        "outputId": "66cabb3f-3c11-444e-d805-ad635a3581e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tWjSe4bVR9Hy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "35zQ0raaTB_4"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = [\"Normal\", \"Porn\"]\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        for label, cls in enumerate(self.classes):\n",
        "            class_dir = os.path.join(root_dir, cls)\n",
        "            for filename in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "\n",
        "                # Ensure it's an image file\n",
        "                if not filename.lower().endswith(('.jpeg')):\n",
        "                    continue\n",
        "\n",
        "                # Try opening the image to check for corruption\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        img.verify()  # Verify image integrity\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.labels.append(label)\n",
        "                except (OSError, UnidentifiedImageError):\n",
        "                    print(f\"Skipping corrupted image: {img_path}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        try:\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "        except (OSError, UnidentifiedImageError):\n",
        "            print(f\"Error loading image: {image_path}\")\n",
        "            return self.__getitem__((index + 1) % len(self))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N5laPhdQXe5f"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random crop and resize\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomGrayscale(p=0.1),  # Randomly convert to grayscale\n",
        "    transforms.GaussianBlur(kernel_size=3),  # Add slight blur\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gufr9KnasIA",
        "outputId": "f9e0e8b3-83fc-48ee-9ffd-da84283f5d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 39446\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/drive/MyDrive/d/Data\"\n",
        "dataset = ImageDataset(data_path, transform=transform)\n",
        "print(\"Number of training examples:\", len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IIVwOntCaxfG",
        "outputId": "2fd22fc4-07d1-4e15-fb27-2261f804a71a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'random' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cccb7e896750>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Label: {'Normal' if label == 0 else 'Porn'}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ],
      "source": [
        "random_index = random.randint(0, len(dataset) - 1)\n",
        "image, label = dataset[random_index]\n",
        "plt.imshow(image.permute(1, 2, 0).numpy())\n",
        "plt.title(f\"Label: {'Normal' if label == 0 else 'Porn'}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6HtDcZ5ayUs",
        "outputId": "73d9c02d-f819-42e1-a452-b655d739b559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 31556, Testing samples: 7890\n"
          ]
        }
      ],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}, Testing samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0iJ7GvieAeu",
        "outputId": "ef553db0-2a8f-46d4-8c71-8a9ba78331ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 97.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "model = models.efficientnet_b0(pretrained=True)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MkKfG-JjjaIr"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi7mZbDJiT-6",
        "outputId": "69c7c66c-df2a-4df5-f0da-d376e6bcbd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/2052.jpeg\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/18877.jpeg\n",
            "Epoch [1/5], Train Loss: 0.0368, Train Accuracy: 98.62%, Val Loss: 0.0453, Val Accuracy: 98.52%\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/2052.jpeg\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/18877.jpeg\n",
            "Epoch [2/5], Train Loss: 0.0260, Train Accuracy: 99.10%, Val Loss: 0.0408, Val Accuracy: 98.61%\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/2052.jpeg\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/18877.jpeg\n",
            "Epoch [3/5], Train Loss: 0.0294, Train Accuracy: 98.87%, Val Loss: 0.0334, Val Accuracy: 98.83%\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/2052.jpeg\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/18877.jpeg\n",
            "Epoch [4/5], Train Loss: 0.0229, Train Accuracy: 99.12%, Val Loss: 0.0403, Val Accuracy: 98.76%\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/2052.jpeg\n",
            "Error loading image: /content/drive/MyDrive/d/Data/Normal/18877.jpeg\n",
            "Epoch [5/5], Train Loss: 0.0211, Train Accuracy: 99.27%, Val Loss: 0.0347, Val Accuracy: 98.66%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "num_epochs = 5\n",
        "patience = 3\n",
        "best_val_loss = float(\"inf\")\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct / total\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0  # Reset counter if validation loss improves\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break  # Stop training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z1v83YCvimYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a666654a-23a5-45cd-bbe2-9fea9c47f153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to efficientnet_b0.pth\n"
          ]
        }
      ],
      "source": [
        "model_path = \"efficientnet_b0.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ue72LcsV99L0"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}